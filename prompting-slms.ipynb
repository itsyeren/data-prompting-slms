{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ§ª KÃ¼Ã§Ã¼k Dil Modeli (SLM) iÃ§in komut istemi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âš ï¸ **Bu not defterini *Colab* Ã¼zerinde Ã§alÄ±ÅŸtÄ±rÄ±n ve *GPU* hÄ±zlandÄ±rmayÄ± etkinleÅŸtirdiÄŸinizden emin olun.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ğŸ§  Hedef\n",
    "**TalimatlarÄ±nÄ±zÄ± iyileÅŸtirmenizi** gerektiren gÃ¶revleri tamamlayarak, **kÃ¼Ã§Ã¼k, yerel olarak Ã§alÄ±ÅŸtÄ±rÄ±lan bir dil modeli** (*Phi-2*) iÃ§in etkili komutlar yazmayÄ± Ã¶ÄŸrenin.\n",
    "\n",
    "---\n",
    "\n",
    "## Î¦ Phi-2?\n",
    "\n",
    "[Phi-2](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/) Microsoft tarafÄ±ndan geliÅŸtirilen, 2,7 milyar parametreye sahip kÃ¼Ã§Ã¼k ve verimli bir dil modelidir. Boyutuna raÄŸmen, akÄ±l yÃ¼rÃ¼tme ve akademik gÃ¶revlerde ÅŸaÅŸÄ±rtÄ±cÄ± derecede iyi performans gÃ¶sterir, bu da onu yerel kullanÄ±m, deneme ve Ã¶ÄŸrenme komut mÃ¼hendisliÄŸi iÃ§in ideal hale getirir.\n",
    "\n",
    "**Mimari**: Phi-2, GPT tarzÄ± modellere benzer, verimlilik ve kÃ¼Ã§Ã¼k Ã¶lÃ§ekli daÄŸÄ±tÄ±m iÃ§in optimize edilmiÅŸ, yalnÄ±zca dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ kod Ã§Ã¶zÃ¼cÃ¼ mimarisi kullanÄ±r.\n",
    "\n",
    "**EÄŸitim**: Ã–zel veya tescilli veriler kullanÄ±lmadan, eÄŸitim ve akÄ±l yÃ¼rÃ¼tme gÃ¶revlerine odaklanan, yÃ¼ksek kaliteli, Ã¶zenle seÃ§ilmiÅŸ sentetik ve filtrelenmiÅŸ web verilerinden oluÅŸan bir veri seti Ã¼zerinde eÄŸitilmiÅŸtir.\n",
    "\n",
    "Phi-2 (ayrÄ±ca eski ve yeni Phi-x modelleri) Hugging Face'ten edinilebilir.\n",
    "\n",
    "Phi-2'yi Ã§Ä±karÄ±m iÃ§in Ã§alÄ±ÅŸtÄ±rmak iÃ§in 6 Gb'den fazla VRAM'e sahip bir CPU'ya ihtiyacÄ±nÄ±z vardÄ±r. CPU'da Ã§alÄ±ÅŸtÄ±rmak mÃ¼mkÃ¼ndÃ¼r (yeterli belleÄŸiniz varsa), ancak Ã§ok yavaÅŸtÄ±r. Bu nedenle bu zorluÄŸu Colab'da Ã§alÄ±ÅŸtÄ±rÄ±yoruz.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§° Kurulum TalimatlarÄ±: Phi-2'yi `pipeline` ile Ã§alÄ±ÅŸtÄ±rma\n",
    "\n",
    "Hugging Face'in `pipeline` arayÃ¼zÃ¼nÃ¼ kullanarak **Microsoft'un Phi-2 modelini (2,7 milyar parametre)** kullanacaksÄ±nÄ±z. Bu, tokenizasyonu manuel olarak iÅŸlemekten daha kolay ve temizdir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdÄ±m 1: Gerekli Paketleri YÃ¼kleyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yerel olarak Ã§alÄ±ÅŸtÄ±rÄ±yorsanÄ±z yorum satÄ±rÄ±nÄ± kaldÄ±rÄ±n.\n",
    "# !pip install transformers accelerate torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdÄ±m 2: Phi-2'yi `pipeline` ile yÃ¼kleyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"microsoft/phi-2\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdÄ±m 3: YanÄ±t OluÅŸturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What causes the seasons?\"\n",
    "response = generator(prompt, max_new_tokens=100)[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metni gÃ¼zel bir ÅŸekilde biÃ§imlendirdiÄŸi iÃ§in yanÄ±tÄ± yazdÄ±rmak yerine Markdown ile gÃ¶rÃ¼ntÃ¼leyelim.\n",
    "from IPython.display import Markdown\n",
    "Markdown(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YanÄ±tlarÄ±mÄ±zÄ±n ne kadar hÄ±zlÄ± tekrarlandÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yor musunuz? Phi 2, yalnÄ±zca kod Ã§Ã¶zÃ¼cÃ¼ iÃ§eren bir modeldir; modelin Ã§Ä±ktÄ±sÄ± (yani sonuÃ§larÄ±) sadece tÃ¼m dizidir.\n",
    "\n",
    "Komut istemlerimizi ve yanÄ±tlarÄ±mÄ±zÄ± dÃ¼zgÃ¼n bir ÅŸekilde yazdÄ±rmak iÃ§in bir yardÄ±mcÄ± iÅŸlev oluÅŸturalÄ±m. ğŸ‘‰ AÅŸaÄŸÄ±daki hÃ¼creyi Ã§alÄ±ÅŸtÄ±rÄ±n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(prompt, response):\n",
    "    \"\"\"Display the prompt and response in a formatted way.\n",
    "    Excludes the prompt in the response to avoid repetition.\"\"\"\n",
    "    display(Markdown(\n",
    "        \"### Prompt:\\n\"\n",
    "        + prompt\n",
    "        + \"\\n### Response:\\n\"\n",
    "        + response[len(prompt):]\n",
    "        + \"\\n\\n---\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§© Komut Ä°steÄŸi GÃ¶revleriniz\n",
    "\n",
    "Her gÃ¶rev iÃ§in aÅŸaÄŸÄ±daki talimatlarÄ± izleyin:\n",
    "\n",
    "ğŸ‘‰ Ä°lk komut isteÄŸini yazÄ±n.\n",
    "\n",
    "ğŸ‘‰ Phi-2 ile Ã§alÄ±ÅŸtÄ±rÄ±n (`max_new_tokens` parametresini denemeniz gerekebilir).\n",
    "\n",
    "ğŸ‘‰ Komut isteÄŸini iyileÅŸtirin.\n",
    "\n",
    "ğŸ‘‰ SonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±rÄ±n.\n",
    "\n",
    "ğŸ‘‰ Ancak o zaman Ã§Ã¶zÃ¼me bakÄ±n.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ GÃ¶rev 1: Temel Soru YanÄ±tlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdÄ±m 1: Ä°lk komut istemini deneyin\n",
    "prompt = \"What causes the seasons?\"\n",
    "response = generator(prompt, max_new_tokens=100)[0][\"generated_text\"]\n",
    "show_results(prompt, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu pek de etkileyici gÃ¶rÃ¼nmÃ¼yor: model sadece metin Ã¼retmeye devam ediyor. EÄŸitim verilerinden bir sonraki tokeni Ã¼retmeyi Ã¶ÄŸrendi ve burada da bunu yapÄ±yor. *SÄ±ra sonu* tokeni Ã¼retmediÄŸi sÃ¼rece devam edecek.\n",
    "\n",
    "Model, GPT-3.5-Turbo gibi RLHF (Ä°nsan Geri Bildiriminden GÃ¼Ã§lendirme Ã–ÄŸrenimi) kullanÄ±larak ince ayar yapÄ±lmamÄ±ÅŸtÄ±r. Bu nedenle, komutlarÄ±mÄ±zÄ± daha yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir ÅŸekilde vermeliyiz.\n",
    "\n",
    "ğŸ‘‰ BaÅŸka bir ÅŸey deneyelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdÄ±m 2: Promptunu iyileÅŸtir\n",
    "prompt2 = \"Explain in simple terms: What causes the seasons?\"\n",
    "response2 = generator(prompt2, max_new_tokens=100)[0][\"generated_text\"]\n",
    "show_results(prompt, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu muhtemelen pek bir ÅŸey deÄŸiÅŸtirmedi, bu yÃ¼zden daha spesifik bir komut istemine ihtiyacÄ±mÄ±z var.\n",
    "\n",
    "Bu gibi durumlarda, modelinize eÄŸitim sÄ±rasÄ±nda olduÄŸu gibi bir komut istemi vermelisiniz. \n",
    "\n",
    "ğŸ‘‰ Bu modelin Soru-Cevap gÃ¶revi iÃ§in eÄŸitim verileriyle nasÄ±l beslenebileceÄŸini dÃ¼ÅŸÃ¼nÃ¼n. Ona bir soru ve bir cevap verilmiÅŸ olurdu. Bunu bilerek, yeni bir komut istemi deneyin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NasÄ±l Ã§alÄ±ÅŸmasÄ± gerektiÄŸini tahmin etmekten bÄ±ktÄ±nÄ±z mÄ±? ğŸ‘‰ Hugging Face'te Microsoft'un Phi-2 modelinin belgelerini bulun ve QA iÃ§in tercih edilen komut istemi formatÄ±nÄ± bulup bulamadÄ±ÄŸÄ±nÄ±zÄ± kontrol edin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ğŸ’¡ Ã‡Ã¶zÃ¼m</summary>\n",
    "  \n",
    " Modelin belgelerini [burada](https://huggingface.co/microsoft/phi-2) bulabilirsiniz.\n",
    "  \n",
    "  GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re komut istemini ÅŸu ÅŸekilde biÃ§imlendirmek gerekiyor:\n",
    "\n",
    "```text\n",
    "  Talimat: Sorunuzu buraya yazÄ±n.\n",
    "  Ã‡Ä±ktÄ±:\n",
    "  ```\n",
    "\n",
    "  Bu Ã§ok satÄ±rlÄ± dizgiyi Python'da kodlamak iÃ§in:\n",
    "```python\n",
    "  # SeÃ§enek 1: yeni satÄ±r baÅŸlatmak iÃ§in \\n kullanarak:\n",
    "  # SeÃ§enek 1: yeni bir satÄ±r baÅŸlatmak iÃ§in \\n kullanarak:\n",
    "  prompt = \"Instruct: This is where your question goes.\\nOutput:\"\n",
    "  # SeÃ§enek 2: Ã§ok satÄ±rlÄ± bir string ile\n",
    "  prompt = \"\"\"Instruct: This is where your question goes.\n",
    "  Output:\"\"\"\n",
    "  # Ä°kinci seÃ§eneÄŸe dikkat edin: ikinci satÄ±rÄ±n baÅŸÄ±na fazladan satÄ±r sonu veya boÅŸluk eklemeyin, bu modelin kafasÄ±nÄ± karÄ±ÅŸtÄ±rÄ±r.\n",
    "  ```\n",
    "\n",
    " Profesyonel ipucu: Soru ile baÅŸlayan tam komut istemini oluÅŸturmak iÃ§in f-string kullanÄ±n.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ğŸ“ GÃ¶rev 2: Ã–zetleme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BazÄ± metinleri Ã¶zetlemeye Ã§alÄ±ÅŸalÄ±m. Bu, Wikipedia'nÄ±n transformatÃ¶rler sayfasÄ±nda yer alan bir alÄ±ntÄ±dÄ±r:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Transformers is a media franchise produced by Japanese toy company Takara Tomy and American toy company Hasbro. It primarily follows the heroic Autobots and the villainous Decepticons, two alien robot factions at war that can transform into other forms, such as vehicles and animals. The franchise encompasses toys, animation, comic books, video games and films. As of 2011, it generated more than Â¥2 trillion ($25 billion) in revenue,[1] making it one of the highest-grossing media franchises of all time.\n",
    "\n",
    "The franchise began in 1984 with the Transformers toy line, comprising transforming mecha toys from Takara's Diaclone and Micro Change toylines rebranded for Western markets.[2] The term \"Generation 1\" (G1) covers both the animated television series The Transformers and the comic book series of the same name, which are further divided into Japanese, British and Canadian spin-offs. Sequels followed, such as the Generation 2 comic book and Beast Wars TV series, which became its own mini-universe. Generation 1 characters have been rebooted multiple times in the 21st century in comics from Dreamwave Productions (starting 2001), IDW Publishing (starting in 2005 and again in 2019), and Skybound Entertainment (beginning in 2023). There have been other incarnations of the story based on different toy lines during and after the 20th century. The first was the Robots in Disguise series, followed by three shows (Armada, Energon, and Cybertron) that constitute a single universe called the \"Unicron Trilogy\".\n",
    "\"\"\"\n",
    "Markdown(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Modele kÄ±sa bir Ã¶zet oluÅŸturmasÄ±nÄ± isteyin. Bunun, `max_new_tokens` ayarÄ±nÄ±z nedeniyle kÄ±sa olmadÄ±ÄŸÄ±ndan emin olun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Input: {text}\\nSummary: \"\n",
    "response = generator(prompt, max_new_tokens=200)[0][\"generated_text\"]\n",
    "show_results(prompt, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ğŸ’¡ Nereden baÅŸlayacaÄŸÄ±nÄ±zÄ± bilmiyor musunuz?</summary>\n",
    "  \n",
    "  Åuradan baÅŸlayabilirsiniz:\n",
    "\n",
    "```text\n",
    "  Ã–zetleyin: Ã–zetlenecek metin burada yer alÄ±r.\n",
    "  ```\n",
    "\n",
    "  Modelin daha kÄ±sa bir Ã¶zet oluÅŸturmasÄ±nÄ± saÄŸlayÄ±n.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ğŸ’¡ Ã‡Ã¶zÃ¼m</summary>\n",
    "  \n",
    "  KÄ±sa bir Ã¶zet elde etmek iÃ§in, bu iyi sonuÃ§lar veriyor gibi gÃ¶rÃ¼nÃ¼yor:\n",
    "\n",
    "```text\n",
    "  Bunu tek bir cÃ¼mleyle Ã¶zetleyin: Ä°ÅŸte metniniz.\n",
    "  ```\n",
    "\n",
    "  Ancak model muhtemelen bu ÅŸekilde eÄŸitilmemiÅŸtir.\n",
    "\n",
    "  AÅŸaÄŸÄ±daki komut, dengeli bir sonuÃ§ Ã¼retiyor gibi gÃ¶rÃ¼nÃ¼yor: Ã§ok kÄ±sa deÄŸil, ama sonsuz da deÄŸil:\n",
    "\n",
    "```text\n",
    "  Input: Ä°ÅŸte metniniz.\n",
    "  Summary:\n",
    "  ```\n",
    "\n",
    "  Ya da bunun kadar kÄ±sa bir ÅŸey:\n",
    "\n",
    "  ```text\n",
    "  Ä°ÅŸte metniniz. TLDR:\n",
    "  ```\n",
    "\n",
    "  Bu muhtemelen, modelin metin kÃ¼mesinde TLDR (Too Long; Didn't Read - Ã‡ok Uzun; OkumadÄ±m) iÃ§eren pek Ã§ok Ã¶rnek gÃ¶rdÃ¼ÄŸÃ¼ iÃ§in iÅŸe yarÄ±yor.\n",
    "  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ğŸ“ GÃ¶rev 3: AdÄ±m AdÄ±m AkÄ±l YÃ¼rÃ¼tme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele sorularÄ± Ã§Ã¶zmesini de isteyebiliriz.\n",
    "\n",
    "ğŸ‘‰ AÅŸaÄŸÄ±daki komutu deneyin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"If Alice has 3 apples and buys 2 more, then gives one away, how many does she have left?\"\n",
    "response = generator(prompt, max_new_tokens=60)[0][\"generated_text\"]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeklediÄŸiniz bu muydu?\n",
    "\n",
    "HayÄ±r, model kod Ã¼retiyor gibi gÃ¶rÃ¼nÃ¼yor. Ä°stediÄŸimiz ÅŸey bu deÄŸil (en azÄ±ndan burada deÄŸil, takipte kalÄ±n).\n",
    "\n",
    "ğŸ‘‰ GerÃ§ek sonucu elde etmek iÃ§in komut istemini iyileÅŸtirmeye Ã§alÄ±ÅŸÄ±n. GPT-4 gibi bÃ¼yÃ¼k bir modelde olduÄŸu gibi komut istemini kullanmanÄ±n burada iÅŸe yaramayacaÄŸÄ±nÄ± fark edeceksiniz. AdÄ±m adÄ±m akÄ±l yÃ¼rÃ¼tmesini istememiz gerekiyor, ardÄ±ndan Ã§Ä±ktÄ±da doÄŸru cevabÄ± bulabileceÄŸimizi umuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ğŸ’¡ Ã‡Ã¶zÃ¼m</summary>\n",
    "  \n",
    "  KÄ±sa bir Ã¶zet iÃ§in, bu iyi sonuÃ§lar veriyor gibi gÃ¶rÃ¼nÃ¼yor:\n",
    "\n",
    "```text\n",
    "  Alice'in 3 elmasÄ± varsa ve 2 tane daha satÄ±n alÄ±p birini baÅŸkasÄ±na verirse, elinde kaÃ§ tane kalÄ±r? AdÄ±m adÄ±m Ã§Ã¶zÃ¼n.\n",
    "  ```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu Ã§ok uzun oldu. Modeli yÃ¶nlendirmek iÃ§in baÅŸka yollar dÃ¼ÅŸÃ¼nebilir misin?\n",
    "\n",
    "ğŸ‘‰ Belgelere tekrar bir gÃ¶z at."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ğŸ’¡ Ã‡Ã¶zÃ¼m</summary>\n",
    "  \n",
    "  Belgelerde, modelin QA stili veya sohbet stili komutlara en iyi ÅŸekilde tepki verdiÄŸini okuyabiliriz.\n",
    "\n",
    "  Bu ÅŸekilde komut vermeye Ã§alÄ±ÅŸÄ±n. ArtÄ±k adÄ±m adÄ±m yaklaÅŸÄ±mÄ±mÄ±z olmayacak, ancak gerÃ§ek cevaba daha hÄ±zlÄ± ulaÅŸabiliriz.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Sohbet stilini kullanmayÄ± deneyin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Ve QA stili:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ğŸ’¡ Ã‡Ã¶zÃ¼m</summary>\n",
    "  \n",
    "  Sohbet stili:\n",
    "```text\n",
    "  Ã–ÄŸretmen: Ä°ÅŸte soru.\n",
    "  Ã–ÄŸrenci:\n",
    "  ```\n",
    "\n",
    "Soru-cevap stili:\n",
    "```text\n",
    "  Instruct: Ä°ÅŸte soru.\n",
    "  Output:\n",
    "  ```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ğŸ“ GÃ¶rev 4: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BazÄ± film eleÅŸtirilerini derecelendirmeyi deneyelim.\n",
    "\n",
    "ğŸ‘‰ [Kaggle'dan IMDB Veri Setini indirin](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?select=IMDB+Dataset.csv) ve Colab'a yÃ¼kleyin. ArdÄ±ndan aÅŸaÄŸÄ±daki hÃ¼creyi Ã§alÄ±ÅŸtÄ±rarak verileri yÃ¼kleyin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "reviews = pd.read_csv(\"./IMDB Dataset.csv\", sep=\",\")['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = reviews[0]  # Bu endeksi kullanarak farklÄ± incelemelerle test edin\n",
    "prompt = f\"Classify the sentiment of this review as Positive, Neutral, or Negative: '{review}'\"\n",
    "response = generator(prompt, max_new_tokens=40)[0][\"generated_text\"]\n",
    "show_results(prompt, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pek iyi deÄŸil, deÄŸil mi? UnutmayÄ±n: bu bir Ã¼retken modeldir, yani sonraki tokenleri Ã¼retir. Komut istemimizde biraz daha akÄ±llÄ± davranmamÄ±z gerekecek.\n",
    "\n",
    "ğŸ‘‰ Ã–nce komut istemini kendiniz iyileÅŸtirmeye Ã§alÄ±ÅŸÄ±n. Modelin sadece duyguyu ve baÅŸka hiÃ§bir ÅŸeyi Ã§Ä±karmamasÄ±nÄ± saÄŸlayabilir misiniz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ğŸ’¡ Ã‡Ã¶zÃ¼m</summary>\n",
    "  \n",
    "  Sonuna `Sentiment:` eklemek harika sonuÃ§lar veriyor:\n",
    "```text\n",
    "  Bu yorumu Pozitif, NÃ¶tr veya Negatif olarak sÄ±nÄ±flandÄ±rÄ±n:\n",
    "\n",
    "  Ä°ÅŸte yorum.\n",
    "\n",
    "  Sentiment:\n",
    "  ```\n",
    "\n",
    "Muhtemelen model bu formattaki verileri gÃ¶rdÃ¼ÄŸÃ¼ iÃ§indir.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ğŸ“ GÃ¶rev 5: Kod oluÅŸturma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Belgeleri okuduÄŸunuzda, Phi-2'nin kod da Ã¼retebileceÄŸini gÃ¶rmÃ¼ÅŸ olabilirsiniz.\n",
    "\n",
    "ğŸ‘‰ Hadi deneyelim: Bu bir Ã¼retken modeldir, bu yÃ¼zden ona kodun baÅŸlangÄ±cÄ±nÄ± veririz ve geri kalanÄ±nÄ± o Ã¼retir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_start = '''\n",
    "def get_weather(location, fahrenheit=False):\n",
    "'''\n",
    "response = generator(code_start, max_new_tokens=200)[0][\"generated_text\"]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VerdiÄŸimiz sÄ±nÄ±rlÄ± bilgiye gÃ¶re fena deÄŸil. NasÄ±l daha iyisini yapabiliriz? Modele daha fazla Ã§alÄ±ÅŸma alanÄ± saÄŸlamak iÃ§in fonksiyon tanÄ±mlamasÄ±ndan sonra ne ekleyebiliriz?\n",
    "\n",
    "ğŸ‘‰ Promptunuzu iyileÅŸtirmeye Ã§alÄ±ÅŸÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ğŸ’¡ Ã‡Ã¶zÃ¼m</summary>\n",
    "  \n",
    "  Docstring: fonksiyonun ne yapmasÄ± gerektiÄŸini aÃ§Ä±klar. Bu, model iÃ§in harika bir talimat gÃ¶revi gÃ¶rÃ¼r.\n",
    "\n",
    "  Bir docstring ekleyin, modele `Open Weather API` kullanmasÄ±nÄ± sÃ¶yleyin ve fahrenheit parametresiyle ne yapmasÄ± gerektiÄŸini aÃ§Ä±klayÄ±n.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Kodu inceleyin. Size doÄŸru gÃ¶rÃ¼nÃ¼yor mu? [Open Weather API belgeleriyle](https://openweathermap.org/current) karÅŸÄ±laÅŸtÄ±rÄ±n.\n",
    "\n",
    "<details>\n",
    "  <summary>ğŸ’¡ Ã‡Ã¶zÃ¼m</summary>\n",
    "  \n",
    "  Kod muhtemelen sorunlu gÃ¶rÃ¼nmÃ¼yor. BÃ¼yÃ¼k olasÄ±lÄ±kla, API'nin `current` uÃ§ noktasÄ±nÄ±n yerleÅŸik coÄŸrafi kodlama iÅŸlevini kullandÄ±ÄŸÄ±nÄ± gÃ¶receksiniz. Belgeleri okuduÄŸunuzda, bu iÅŸlevin kullanÄ±mdan kaldÄ±rÄ±ldÄ±ÄŸÄ±nÄ± ve artÄ±k kullanÄ±lmamasÄ± gerektiÄŸini gÃ¶receksiniz.\n",
    "\n",
    "Kodunuz ne kadar Ã¶zel hale gelirse, iyi sonuÃ§lar alma olasÄ±lÄ±ÄŸÄ±nÄ±z o kadar azalÄ±r.\n",
    "\n",
    "</details>\n",
    "\n",
    "LLM'lerden Ã¼retilen kodu ve kesinlikle SLM'den Ã¼retilen kodu her zaman kontrol etmelisiniz: SLM Ã§ok daha az veri ile eÄŸitilmiÅŸtir.\n",
    "\n",
    "ğŸ‘‰ Kod Ã¼retimi iÃ§in [Phi-2'nin sÄ±nÄ±rlamalarÄ±](https://huggingface.co/microsoft/phi-2#limitations-of-phi-2) hakkÄ±nda daha fazla bilgi edinmek iÃ§in Hugging Face'deki belgelere gÃ¶z atÄ±n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ğŸ Tebrikler! ArtÄ±k farklÄ± kullanÄ±m senaryolarÄ± iÃ§in yerel olarak Ã§alÄ±ÅŸan Ã¼retken kÃ¼Ã§Ã¼k dil modelini nasÄ±l kullanacaÄŸÄ±nÄ±zÄ± biliyorsunuz."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
